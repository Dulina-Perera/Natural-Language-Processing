{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from IPython.display import display\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline.attributeruler import AttributeRuler\n",
    "from spacy.tokens.doc import Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating -> eat\n",
      "eats -> eat\n",
      "eat -> eat\n",
      "eaten -> eaten\n",
      "ate -> ate\n",
      "adjustable -> adjust\n",
      "rafting -> raft\n",
      "ability -> abil\n",
      "meeting -> meet\n",
      "better -> better\n"
     ]
    }
   ],
   "source": [
    "stemmer: PorterStemmer = PorterStemmer()\n",
    "# stemmer: SnowballStemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "words: list[str] = [\n",
    "\t\"eating\",\n",
    "\t\"eats\",\n",
    "\t\"eat\",\n",
    "\t\"eaten\",\n",
    "\t\"ate\",\n",
    "\t\"adjustable\",\n",
    "\t\"rafting\",\n",
    "\t\"ability\",\n",
    "\t\"meeting\",\n",
    "\t\"better\"\n",
    "]\n",
    "\n",
    "for word in words:\n",
    "\tprint(f\"{word} -> {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating -> eat (9837207709914848172)\n",
      "eats -> eat (9837207709914848172)\n",
      "eat -> eat (9837207709914848172)\n",
      "eaten -> eat (9837207709914848172)\n",
      "ate -> eat (9837207709914848172)\n",
      "adjustable -> adjustable (6033511944150694480)\n",
      "rafting -> raft (7154368781129989833)\n",
      "ability -> ability (11565809527369121409)\n",
      "meeting -> meeting (14798207169164081740)\n",
      "better -> well (4525988469032889948)\n"
     ]
    }
   ],
   "source": [
    "nlp: English = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc: Doc = nlp(\" \".join(words))\n",
    "\n",
    "for token in doc:\n",
    "\tprint(f\"{token.text} -> {token.lemma_} ({token.lemma})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mando -> Mando\n",
      "talked -> talk\n",
      "for -> for\n",
      "3 -> 3\n",
      "hours -> hour\n",
      "although -> although\n",
      "talking -> talk\n",
      "is -> be\n",
      "n't -> not\n",
      "his -> his\n",
      "thing -> thing\n",
      ". -> .\n",
      "He -> he\n",
      "became -> become\n",
      "talkative -> talkative\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing. He became talkative.\")\n",
    "\n",
    "for token in doc:\n",
    "\tprint(f\"{token.text} -> {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "display(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro -> Brother\n",
      ", -> ,\n",
      "you -> you\n",
      "wanna -> wanna\n",
      "go -> go\n",
      "? -> ?\n",
      "Brah -> Brother\n",
      ", -> ,\n",
      "do -> do\n",
      "n't -> not\n",
      "say -> say\n",
      "no -> no\n",
      "! -> !\n",
      "I -> I\n",
      "am -> be\n",
      "exhausted -> exhausted\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "ar: AttributeRuler = nlp.get_pipe(\"attribute_ruler\")\n",
    "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted.\")\n",
    "\n",
    "for token in doc:\n",
    "\tprint(f\"{token.text} -> {token.lemma_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
